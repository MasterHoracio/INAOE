{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bi-GRU Example PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxhyz88tHsUK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.legacy import datasets\n",
        "from torchtext.legacy.data import Field, LabelField, BucketIterator\n",
        "from torch.nn.utils.rnn import pad_sequence, pad_packed_sequence, pack_padded_sequence\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed_all(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT = Field(tokenize = 'spacy', lower = True) # Indicamos que queremos el texto tokenizado\n",
        "LABEL = LabelField(dtype = torch.int64) # Indicamos que la etiqueta la queremos como un entero\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL) # Descargar el dataset IMDB"
      ],
      "metadata": {
        "id": "gRvre73pHgRn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8979e52-e91c-42c2-cd42-ff3dc70201ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 84.1M/84.1M [00:02<00:00, 30.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar el número de instancias de entrenamiento y prueba\n",
        "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
        "print(f\"Number of testing examples: {len(test_data.examples)}\")\n",
        "\n",
        "# Mostrar como ejemplo la primera instancia\n",
        "print(vars(train_data.examples[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVVYQKXvIYHo",
        "outputId": "5515c19d-274d-4fd5-ab9d-16a6692a2745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n",
            "{'text': ['it', \"'s\", 'a', 'very', 'nice', 'movie', 'and', 'i', 'would', 'definitely', 'recommend', 'it', 'to', 'everyone', '.', 'but', 'there', 'are', '2', 'minus', 'points', ':', '-', 'the', 'level', 'of', 'the', 'stories', 'has', 'a', 'large', 'spectrum', '.', 'some', 'of', 'the', 'scenes', 'are', 'very', 'great', 'and', 'some', 'are', 'just', 'boring', '.', '-', 'a', 'lot', 'of', 'stories', 'are', 'not', 'self', '-', 'contained', '(', 'if', 'you', 'compare', 'to', 'f.e', '.', 'coffee', 'and', 'cigarettes', ',', 'where', 'each', 'story', 'has', 'a', 'point', ',', 'a', 'message', ',', 'a', 'punchline', 'or', 'however', 'you', 'wanna', 'call', 'it', ')', 'but', 'well', ',', 'most', 'stories', 'are', 'really', 'good', ',', 'some', 'are', 'great', 'and', 'overall', 'it', \"'s\", 'one', 'of', 'the', 'best', 'movies', 'this', 'year', 'for', 'sure!<br', '/><br', '/>annoying', ',', 'that', 'i', 'have', 'to', 'fill', '10', 'lines', 'at', 'minimum', ',', 'i', 'have', \"n't\", 'got', 'more', 'to', 'say', 'and', 'i', 'do', \"n't\", 'want', 'to', 'start', 'analyzing', 'the', 'single', 'sequences', '...', '<br', '/><br', '/>well', ',', 'i', 'think', 'that', \"'s\", 'it', '!'], 'label': 'pos'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Construir vocabulario del conjunto de entrenamiento\n",
        "TEXT.build_vocab(train_data, max_size=10000, min_freq=5, vectors=\"glove.6B.100d\")  # Usando word embeddings pre-entrenados\n",
        "LABEL.build_vocab(train_data, min_freq = 5)\n",
        "\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnQ__BQzLFhe",
        "outputId": "f288db44-7897-4cb2-94eb-cca502e7b713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:40, 5.38MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:15<00:00, 26152.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens in TEXT vocabulary: 10002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Asignamos el dispositivo en el que se entrenará el modelo propuesto\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Iterador de entrenamiento y prueba\n",
        "train_iterator, test_iterator = BucketIterator.splits(\n",
        "      (train_data, test_data), \n",
        "      batch_size = BATCH_SIZE, \n",
        "      device = device)"
      ],
      "metadata": {
        "id": "jqypeMTZM0Dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la clase del modelo\n",
        "class BiGRU(nn.Module):\n",
        "  def __init__(self, input_size, vocab_size, output_dim, emb_dim, hidden_dim, n_layers, dropout_rate):\n",
        "    # vocab_size <--- tamaño del vocabulario\n",
        "    # output_dim <--- ([positive, negative]) == 2\n",
        "    # emb_dim <--- dimensión de la matríz de embeddings\n",
        "    # hidden_dim <--- dimensión de la codificación\n",
        "    # n_layers <--- número de capas en la GRU\n",
        "    \n",
        "    super(BiGRU, self).__init__()\n",
        "    self.n_layers = n_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.input_size = input_size\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
        "    self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_dim, \n",
        "                          num_layers=n_layers, bidirectional=True)\n",
        "    self.fc1 = nn.Linear(hidden_dim*2, 64)\n",
        "    self.fc2 = nn.Linear(64, output_dim)\n",
        "    \n",
        "    self.relu = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "  def forward(self, text):\n",
        "    embedded = self.dropout(self.embedding(text))\n",
        "\n",
        "    output, hn = self.gru(embedded)\n",
        "    hn = torch.cat([h for h in hn], dim=-1)\n",
        "    \n",
        "    output = self.fc1(hn)\n",
        "    output = self.fc2(self.relu(output))\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "QQQ1rNrINssP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicialización de hiperparámetros\n",
        "INPUT_SIZE = 100\n",
        "VOCAB_SIZE = len(TEXT.vocab)\n",
        "OUTPUT_DIM = len(LABEL.vocab)\n",
        "EMBBEDING_DIM = 100\n",
        "HID_DIM = 128\n",
        "N_LAYERS = 1\n",
        "DROPOUT_RATE = 0.10\n",
        "LEARNING_RATE = 1e-3\n",
        "\n",
        "# Inicializar nuestro modelo\n",
        "model = BiGRU(INPUT_SIZE, VOCAB_SIZE, OUTPUT_DIM, EMBBEDING_DIM, HID_DIM, N_LAYERS, DROPOUT_RATE).to(device)\n",
        "\n",
        "# Cargar los word embedding pre-entrenados\n",
        "model.embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
        "\n",
        "# Definimos el optimizados\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Definimos un decremento de tasa de aprendizaje (opcional)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
        "\n",
        "# Definimos la función de pérdida\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "m9QN_DQzTP51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcula el total de etiquetas correctamente clasificadas\n",
        "def sum_correct(preds, labels):\n",
        "  pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "  return np.sum(pred_flat == labels_flat), pred_flat, labels_flat\n",
        "\n",
        "# Función para el entrenamiento de nuestro modelo\n",
        "def train(model, iterator, optimizer=optimizer, criterion=criterion, clip=1):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    total_correct = 0\n",
        "    total_count = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        src = batch.text.to(device)\n",
        "        trg = batch.label.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(src)\n",
        "\n",
        "        total_correct += torch.sum(torch.eq(output.argmax(1), trg))\n",
        "        total_count += len(trg)\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward() \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    \n",
        "    print(f'Train accuracy: {(total_correct/total_count):.6f}')\n",
        "    mean_loss = epoch_loss / len(iterator)\n",
        "    scheduler.step(mean_loss)\n",
        "    return mean_loss # Pérdida promedio"
      ],
      "metadata": {
        "id": "XiMiiszTT-ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ciclo de entrenamiento\n",
        "total_epoch = 5\n",
        "for epoch in range(total_epoch):\n",
        "  result = train(model=model, iterator=train_iterator)\n",
        "  print(f'Epoch {epoch + 1} / {total_epoch}, Mean loss: {result:.6f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SROqEXOeVSiJ",
        "outputId": "de52d03f-5d50-465c-aa99-f5ee76b448c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy: 0.749280\n",
            "Epoch 1 / 5, Mean loss: 0.493229\n",
            "Train accuracy: 0.897120\n",
            "Epoch 2 / 5, Mean loss: 0.262159\n",
            "Train accuracy: 0.930400\n",
            "Epoch 3 / 5, Mean loss: 0.183681\n",
            "Train accuracy: 0.951160\n",
            "Epoch 4 / 5, Mean loss: 0.137071\n",
            "Train accuracy: 0.967400\n",
            "Epoch 5 / 5, Mean loss: 0.097001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_correct = 0\n",
        "total_count = 0\n",
        "model_prediction = []\n",
        "ground_truth = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i, batch in enumerate(test_iterator):\n",
        "    src = batch.text.to(device)\n",
        "    trg = batch.label.to(device)\n",
        "    output = model(src)\n",
        "\n",
        "    # Mover las etiquetas y las predicciones a la cpu\n",
        "    output = output.detach().cpu().numpy()\n",
        "    label_ids = trg.to('cpu').numpy()\n",
        "\n",
        "    # Sumar las predicciones correctas\n",
        "    correct, predictions, labels = sum_correct(output, label_ids)\n",
        "    model_prediction.append(predictions.tolist())\n",
        "    ground_truth.append(labels.tolist())\n",
        "    total_correct += correct\n",
        "    total_count += len(trg)\n",
        "\n",
        "print(f'Test accuracy: {(total_correct/total_count):.6f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtlcjHGHw68L",
        "outputId": "90648111-71ab-461d-f4cb-dd8af38897d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.893600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reporte de clasificación\n",
        "model_prediction = [item for sublist in model_prediction for item in sublist]\n",
        "ground_truth = [item for sublist in ground_truth for item in sublist]\n",
        "print(classification_report(ground_truth, model_prediction, labels=[0 ,1], digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IunPREpR3C_Q",
        "outputId": "755ed658-9fb3-48a1-a01b-474bae16563a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9069    0.8772    0.8918     12500\n",
            "           1     0.8811    0.9100    0.8953     12500\n",
            "\n",
            "    accuracy                         0.8936     25000\n",
            "   macro avg     0.8940    0.8936    0.8936     25000\n",
            "weighted avg     0.8940    0.8936    0.8936     25000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}